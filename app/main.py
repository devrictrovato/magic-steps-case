# main.py
# ============================================================
# Magic Steps â€” API FastAPI
# ============================================================
#
#   ExecuÃ§Ã£o:
#       uvicorn main:app --host 0.0.0.0 --port 8000 --reload
#
#   Swagger UI:
#       http://localhost:8000/docs
#
#   ReDoc:
#       http://localhost:8000/redoc
#
# ============================================================

from __future__ import annotations

import logging
from pathlib import Path

# make project root and src directory importable for top-level modules
import sys
root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(root))
sys.path.insert(0, str(root / "src"))
from typing import Dict, List, Any, Optional


import torch
import torch.nn as nn
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

# â”€â”€ logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s â€” %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger("magic_steps_api")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURAÃ‡Ã•ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Caminhos â€” main.py vive em app/, mas out/ estÃ¡ na raiz do projeto
BASE_DIR          = Path(__file__).resolve().parent.parent   # sobe de app/ â†’ raiz
MODEL_PATH        = BASE_DIR / "app/model" / "model_magic_steps_dl.pt"
PREPROCESSOR_PATH = BASE_DIR / "out" / "preprocessor.joblib"

# â”€â”€ contexto global â€” importado do mÃ³dulo neutro â”€â”€â”€â”€â”€â”€â”€â”€â”€
from context import DEVICE, _MODEL_CONTEXT, get_model_context  # noqa: F401


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUITETURA DO MODELO  (espelhada do train.py)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MagicStepsNet(nn.Module):
    """
    Rede neural classificadora.

    Arquitetura: camadas fully-connected empilhadas com
    ReLU â†’ BatchNorm â†’ Dropout apÃ³s cada hidden layer.
    SaÃ­da: 1 logit (sigmoid aplicado na inferÃªncia).
    """

    def __init__(
        self,
        input_dim:     int,
        hidden_layers: List[int],
        dropout:       float,
    ):
        super().__init__()

        layers: List[nn.Module] = []
        prev_dim = input_dim

        for h in hidden_layers:
            layers.extend([
                nn.Linear(prev_dim, h),
                nn.ReLU(),
                nn.BatchNorm1d(h),
                nn.Dropout(dropout),
            ])
            prev_dim = h

        layers.append(nn.Linear(prev_dim, 1))
        self.net = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.net(x).squeeze(1)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CARREGAMENTO DO MODELO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_model() -> None:
    """
    Carrega o checkpoint .pt salvo pelo train.py e
    preenche o contexto global com modelo + metadados.
    """
    if not MODEL_PATH.exists():
        logger.error(
            "Arquivo de modelo nÃ£o encontrado: %s", MODEL_PATH
        )
        logger.warning("A API iniciarÃ¡ sem modelo â€” /predict retornarÃ¡ 503.")
        return

    logger.info("Carregando modelo de %s â€¦", MODEL_PATH)

    checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)

    input_dim   = checkpoint["input_dim"]
    best_params = checkpoint["best_params"]

    model = MagicStepsNet(
        input_dim=input_dim,
        hidden_layers=best_params["hidden_layers"],
        dropout=best_params["dropout"],
    ).to(DEVICE)

    model.load_state_dict(checkpoint["model_state_dict"])
    model.eval()  # desativa dropout e normaliza BatchNorm

    _MODEL_CONTEXT["model"]       = model
    _MODEL_CONTEXT["input_dim"]   = input_dim
    _MODEL_CONTEXT["best_params"] = best_params

    logger.info(
        "âœ… Modelo carregado â€” input_dim=%d | layers=%s | dropout=%.2f | device=%s",
        input_dim,
        best_params["hidden_layers"],
        best_params["dropout"],
        DEVICE,
    )


def load_preprocessor() -> None:
    """
    Carrega o ColumnTransformer (MinMaxScaler + OrdinalEncoder)
    salvo pelo preprocessing.py e o coloca no contexto global.
    """
    if not PREPROCESSOR_PATH.exists():
        logger.error("Preprocessador nÃ£o encontrado: %s", PREPROCESSOR_PATH)
        logger.warning("A API iniciarÃ¡ sem preprocessador â€” /predict retornarÃ¡ 503.")
        return

    import joblib  # noqa: E402 â€” importado aqui para nÃ£o pesar no topo

    preprocessor = joblib.load(PREPROCESSOR_PATH)
    _MODEL_CONTEXT["preprocessor"] = preprocessor

    # log das features que o preprocessador conhece
    num_cols = preprocessor.transformers_[0][2]   # MinMaxScaler
    cat_cols = preprocessor.transformers_[1][2]   # OrdinalEncoder
    logger.info(
        "âœ… Preprocessador carregado â€” %d numÃ©ricas, %d categÃ³ricas | output_dim=%d",
        len(num_cols), len(cat_cols), len(num_cols) + len(cat_cols),
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# APLICAÃ‡ÃƒO FASTAPI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€ instÃ¢ncia â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(
    title="ğŸ¯ Magic Steps â€” Prediction API",
    description=(
        "API de inferÃªncia para o modelo de prediÃ§Ã£o de "
        "**atingimento do Valor PrognÃ³stico (PV)** â€” Projeto PEDE 2024.\n\n"
        "### Como usar\n"
        "1. Consulte `GET /features` para ver as features esperadas, suas descriÃ§Ãµes e **intervalos vÃ¡lidos**.\n"
        "2. Envie os dados do aluno com **valores reais** (ex: `nota_cg: 430`, `pedra_modal: \"ametista\"`) "
        "para `POST /predict`. A API aplica o preprocessador internamente.\n"
        "3. Para processamento em lote use `POST /predict/batch` (atÃ© 500 alunos).\n\n"
        "### PrÃ©-processamento interno\n"
        "VocÃª **nÃ£o** precisa normalizar nada. O `preprocessor.joblib` (MinMaxScaler + OrdinalEncoder) "
        "Ã© aplicado automaticamente antes da inferÃªncia do modelo.\n\n"
        "### Limiar de classificaÃ§Ã£o\n"
        "O limiar padrÃ£o Ã© **0.5**. Use `PUT /thresholds` para ajustÃ¡-lo "
        "sem reiniciar a API."
    ),
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
)

# â”€â”€ CORS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],          # ajuste para produÃ§Ã£o
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€ registra rotas do router â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from routes import router as prediction_router   # noqa: E402
app.include_router(prediction_router)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EVENTOS DE CICLO DE VIDA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.on_event("startup")
async def startup_event():
    """Carrega modelo + preprocessador no momento em que a aplicaÃ§Ã£o sobe."""
    logger.info("ğŸš€ Iniciando Magic Steps API â€¦")
    load_model()
    load_preprocessor()
    logger.info("ğŸŸ¢ API pronta para receber requisiÃ§Ãµes.")


@app.on_event("shutdown")
async def shutdown_event():
    """Libera recursos ao derrubar a aplicaÃ§Ã£o."""
    logger.info("ğŸ”´ Encerrando Magic Steps API â€¦")
    _MODEL_CONTEXT["model"]        = None
    _MODEL_CONTEXT["preprocessor"] = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXECUÃ‡ÃƒO DIRETA  (python main.py)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import uvicorn  # noqa: E402

    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info",
    )